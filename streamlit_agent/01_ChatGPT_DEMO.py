import streamlit as st
from langchain.llms import OpenAI
import os
from dotenv import load_dotenv
import openai
#reference:https://zenn.dev/nishijima13/articles/3b1a50b8728261
import os
from dotenv import load_dotenv
from langchain.chat_models import AzureChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage

from langchain.llms import AzureOpenAI
import openai

#streming by langcahin
from langchain.llms import OpenAI
from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.callbacks.base import BaseCallbackHandler

# .envãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
load_dotenv(os.path.join(os.path.dirname(__file__), '..', '.env'))
openai.api_key = os.environ["OPENAI_API_KEY"]

def simple_response_chatgpt(
    model_name: str,
    user_msg: str,
):
    """ChatGPTã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å–å¾—

    Args:
        user_msg (str): ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã€‚
    """
    response = openai.ChatCompletion.create(
        model=model_name,
        messages=[
            {"role": "user", "content": user_msg},
        ],
        stream=True,
    )
    print(f"test:{model_name}")
    print(f"response:{response}")
    return response


#ãƒ¯ã‚¤ãƒ‰è¡¨ç¤º
st.set_page_config(layout="wide")

#ã‚¿ã‚¤ãƒˆãƒ«ã‚’è¡¨ç¤º
st.title('ğŸ¦œChatGPT DEMO')
st.subheader('ã¾ã memoryæ©Ÿèƒ½ã¯æœªå®Ÿè£…' )

model_name = st.radio(label='ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ã­',
                 options=('gpt-3.5-turbo', 'gpt-4'),
                 index=0,
                 horizontal=True,
)
 
# å®šæ•°å®šç¾©
USER_NAME = "user"
ASSISTANT_NAME = "assistant"

# ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’ä¿å­˜ã—ãŸã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’åˆæœŸåŒ–
if "chat_log" not in st.session_state:
    st.session_state.chat_log = []



user_msg = st.chat_input("ã“ã“ã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›")
if user_msg:
    # ä»¥å‰ã®ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’è¡¨ç¤º
    for chat in st.session_state.chat_log:
        with st.chat_message(chat["name"]):
            st.write(chat["msg"])

    # æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    with st.chat_message(USER_NAME):
        st.write(user_msg)

    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
    response = simple_response_chatgpt(model_name,user_msg)
    with st.chat_message(ASSISTANT_NAME):
        assistant_msg = ""
        assistant_response_area = st.empty()
        for chunk in response:
            # å›ç­”ã‚’é€æ¬¡è¡¨ç¤º
            tmp_assistant_msg = chunk["choices"][0]["delta"].get("content", "")
            assistant_msg += tmp_assistant_msg
            assistant_response_area.write(assistant_msg)

    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’è¿½åŠ 
    st.session_state.chat_log.append({"name": USER_NAME, "msg": user_msg})
    st.session_state.chat_log.append({"name": ASSISTANT_NAME, "msg": assistant_msg})